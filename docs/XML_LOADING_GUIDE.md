# ClinVar XML Loading Guide (v8.2.0)

**Complete implementation of Phase 1, 2, and 3!**

---

## Quick Start

### **Best for Low-Memory Systems (<8GB RAM)**

```python
from pathlib import Path
from varidex.io.loaders.clinvar import load_clinvar_file
from varidex.io.matching_improved import get_user_chromosomes

# Load user genome first
user_df = load_user_genome('23andme.txt')

# Extract chromosomes (e.g., {' 1', '7', '19'})
user_chromosomes = get_user_chromosomes(user_df)

# Load ClinVar XML with indexed mode (30-60s, <500MB RAM)
clinvar_df = load_clinvar_file(
    Path('clinvar/ClinVarVCVRelease.xml'),  # Must be uncompressed
    user_chromosomes=user_chromosomes,
)
```

**Requirements:**
- Uncompressed XML (decompress with `gunzip -k file.xml.gz`)
- First run: 20-30 min to build index (one-time)
- Subsequent runs: 30-60 seconds, <500MB RAM

---

## Performance Comparison

| Mode | Time | RAM | Requirements | Best For |
|------|------|-----|--------------|----------|
| **VCF** | 2-3 min | 1-2GB | VCF file | Most users âœ… |
| **Streaming** | 5-8 min | 2-4GB | Any XML | Full dataset |
| **Lazy** | 1-2 min | 500MB-1GB | Chromosome filter | 23andMe |
| **Indexed** | 30-60s | <500MB | Uncompressed XML | Low memory âœ… |

---

## Three Loading Modes

### **Mode 1: Streaming (Phase 1)**

**When it works:**
- You have 4-8GB+ RAM
- Don't mind waiting 5-8 minutes
- Any XML file (compressed or not)

**Usage:**
```python
from pathlib import Path
from varidex.io.loaders.clinvar import load_clinvar_file

# Load full dataset (streaming mode)
df = load_clinvar_file(Path('clinvar/ClinVarVCVRelease.xml.gz'))

# Result: ~4.3M variants in 5-8 minutes
```

**Pros:**
- Works with compressed `.xml.gz` files
- No preprocessing needed
- Gets all variant types (SVs, CNVs, etc.)

**Cons:**
- Slowest mode (5-8 minutes)
- High memory usage (2-4GB peak)
- May crash on low-memory systems

---

### **Mode 2: Lazy Loading (Phase 2)**

**When it works:**
- You have user genome data (23andMe, AncestryDNA)
- User has 3-10 chromosomes genotyped
- Want 4-8x speedup over full load

**Usage:**
```python
from pathlib import Path
from varidex.io.loaders.clinvar import load_clinvar_file
from varidex.io.loaders.user_genome import load_user_genome
from varidex.io.matching_improved import get_user_chromosomes

# Step 1: Load user genome
user_df = load_user_genome('data/23andme_genome.txt')

# Step 2: Extract chromosomes
user_chromosomes = get_user_chromosomes(user_df)
print(f"User has variants on: {sorted(user_chromosomes)}")
# Output: User has variants on: ['1', '7', '19']

# Step 3: Load only those chromosomes from ClinVar
clinvar_df = load_clinvar_file(
    Path('clinvar/ClinVarVCVRelease.xml.gz'),
    user_chromosomes=user_chromosomes,  # Filter to user's chromosomes
)

# Result: ~400K variants in 1-2 minutes (instead of 4.3M in 5-8 min)
```

**Pros:**
- 4-8x faster than full load
- Lower memory usage
- Works with compressed files
- Auto-filters to relevant data

**Cons:**
- Still streams full file (just filters more)
- Not as fast as indexed mode
- Requires user genome first

---

### **Mode 3: Indexed (Phase 3)** â­ BEST FOR LOW MEMORY

**When it works:**
- You have uncompressed XML
- You have chromosome filter
- Low memory system (<8GB RAM)
- Want fastest possible loads

**Usage:**

**First Time Setup (20-30 minutes, one-time):**
```bash
# Decompress XML if needed
cd clinvar/
gunzip -k ClinVarVCVRelease.xml.gz
# Creates: ClinVarVCVRelease.xml (~70GB uncompressed)
```

**Every Load After (30-60 seconds):**
```python
from pathlib import Path
from varidex.io.loaders.clinvar import load_clinvar_file
from varidex.io.matching_improved import get_user_chromosomes

# Load user genome
user_df = load_user_genome('23andme.txt')

# Extract chromosomes
user_chromosomes = get_user_chromosomes(user_df)

# Load with indexed mode (auto-detected)
clinvar_df = load_clinvar_file(
    Path('clinvar/ClinVarVCVRelease.xml'),  # UNCOMPRESSED
    user_chromosomes=user_chromosomes,  # REQUIRED for indexed mode
)

# First run: Builds index (20-30 min) + loads variants (30-60s)
# Subsequent runs: Just loads variants (30-60s)
```

**Index is cached:**
```
clinvar/
â”œâ”€â”€ ClinVarVCVRelease.xml              # 70GB uncompressed
â””â”€â”€ ClinVarVCVRelease.xml.index.json.gz  # 50MB index (cached)
```

**Pros:**
- âš¡ Fastest: 30-60 seconds
- ðŸ’¾ Lowest memory: <500MB
- ðŸ’¾ One-time indexing, reused forever
- ðŸŽ¯ Direct chromosome seeking (no scanning)

**Cons:**
- Requires uncompressed XML (~70GB disk)
- First run takes 20-30 min to build index
- Requires chromosome filter (can't load all)

---

## Smart Mode Selection

**VariDex automatically chooses the best mode:**

```python
# It checks these conditions in order:

# 1. Can use indexed mode?
if (filepath.endswith('.xml')  # Uncompressed
    and user_chromosomes is not None):  # Has filter
    use_indexed_mode()  # 30-60s, <500MB

# 2. Otherwise, use streaming
else:
    use_streaming_mode()  # 5-8min, 2-4GB
```

**You don't need to choose manually!** Just provide the parameters:

```python
# This will auto-select indexed mode
df = load_clinvar_file(
    Path('file.xml'),  # Uncompressed
    user_chromosomes={'1', '7'},  # Filtered
)
# Uses: Indexed mode (fast, low memory)

# This will use streaming
df = load_clinvar_file(
    Path('file.xml.gz'),  # Compressed
)
# Uses: Streaming mode (slow, high memory)
```

---

## Complete Example Workflow

```python
#!/usr/bin/env python3
"""
Complete workflow: User genome + ClinVar matching with optimal loading.
"""

from pathlib import Path
from varidex.io.loaders.user_genome import load_user_genome
from varidex.io.loaders.clinvar import load_clinvar_file
from varidex.io.matching_improved import get_user_chromosomes, match_variants_hybrid
import time

# Step 1: Load user genome
print("Loading user genome...")
user_df = load_user_genome('data/genome_Michal_Full_20250117025007.txt')
print(f"User variants: {len(user_df):,}")

# Step 2: Extract chromosomes for lazy loading
user_chromosomes = get_user_chromosomes(user_df)
print(f"User chromosomes: {sorted(user_chromosomes)}")
print(f"Will load {len(user_chromosomes)} chromosomes instead of all 24")
print(f"Expected speedup: {24/len(user_chromosomes):.1f}x\n")

# Step 3: Load ClinVar (indexed mode - FAST!)
print("Loading ClinVar XML (indexed mode)...")
start = time.time()

clinvar_df = load_clinvar_file(
    Path('clinvar/ClinVarVCVRelease.xml'),  # Uncompressed for indexed mode
    user_chromosomes=user_chromosomes,  # Enables indexed mode
)

elapsed = time.time() - start
print(f"Loaded {len(clinvar_df):,} variants in {elapsed:.1f}s\n")

# Step 4: Match variants
print("Matching variants...")
matched_df, rsid_matches, coord_matches = match_variants_hybrid(
    clinvar_df,
    user_df,
    clinvar_type="xml",
    user_type="23andme",
)

print(f"\nMatches found: {len(matched_df):,}")
print(f"  - rsID matches: {rsid_matches:,}")
print(f"  - Coordinate matches: {coord_matches:,}")

# Step 5: Filter to pathogenic variants
pathogenic = matched_df[
    matched_df['clinical_sig'].str.contains(
        'Pathogenic|Likely pathogenic',
        case=False,
        na=False
    )
]

print(f"\nPathogenic variants: {len(pathogenic):,}")
print("\nTop pathogenic variants:")
print(pathogenic[['gene', 'clinical_sig', 'match_confidence']].head(10))
```

**Expected output:**
```
Loading user genome...
User variants: 650,000
User chromosomes: ['1', '7', '19']
Will load 3 chromosomes instead of all 24
Expected speedup: 8.0x

Loading ClinVar XML (indexed mode)...
Building index (first run, 20-30 min)...
Indexing XML: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.30M/4.30M [22:34<00:00, 3.17kvar/s]
Index built: 4,300,000 variants across 24 chromosomes
Index saved: 52.3 MB
Loading variants: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 425K/425K [00:38<00:00, 11.1kvar/s]
Loaded 425,137 variants in 38.2s

Matching variants...
Matches found: 1,847
  - rsID matches: 1,203
  - Coordinate matches: 644

Pathogenic variants: 12
```

---

## Troubleshooting

### "Process Killed" / Out of Memory

**Problem:** Streaming mode uses too much RAM.

**Solution 1: Use Indexed Mode**
```bash
# Decompress XML
gunzip -k ClinVarVCVRelease.xml.gz

# Use indexed mode (requires uncompressed XML)
python your_script.py  # Will auto-detect and use indexed mode
```

**Solution 2: Use VCF Instead**
```python
# VCF uses less memory
df = load_clinvar_file(Path('clinvar/clinvar_GRCh38.vcf.gz'))
```

---

### "Indexed mode failed, falling back to streaming"

**Causes:**
1. XML is compressed (`.xml.gz`)
2. No chromosome filter provided
3. Index is corrupt

**Solutions:**
```python
# Make sure file is uncompressed
Path('file.xml').exists()  # Not file.xml.gz

# Make sure you provide chromosomes
user_chromosomes = get_user_chromosomes(user_df)
df = load_clinvar_file(path, user_chromosomes=user_chromosomes)

# Rebuild index if corrupt
from varidex.io.indexers import build_xml_index
index = build_xml_index(Path('file.xml'), force_rebuild=True)
```

---

### First Run Takes 20-30 Minutes

**This is normal!** Indexed mode must build the index on first run.

**Progress:**
```
Indexing XML: 42%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ        | 1.81M/4.30M [09:12<11:32, 3.6kvar/s]
```

**Subsequent runs:** 30-60 seconds (index is cached)

---

### Want to Force Streaming Mode?

```python
from varidex.io.loaders.clinvar_xml import _load_clinvar_xml_streaming

# Bypass smart selection, force streaming
df = _load_clinvar_xml_streaming(
    Path('file.xml'),
    user_chromosomes=None,
)
```

---

## Disk Space Requirements

| File | Size | Purpose |
|------|------|----------|
| `ClinVarVCVRelease.xml.gz` | ~4GB | Compressed download |
| `ClinVarVCVRelease.xml` | ~70GB | Uncompressed (for indexed mode) |
| `ClinVarVCVRelease.xml.index.json.gz` | ~50MB | Cached index |
| **Total for indexed mode** | **~74GB** | Uncompressed + index |

**Space-saving tip:**
```bash
# Keep only uncompressed + index, delete .gz
gunzip -k ClinVarVCVRelease.xml.gz  # Creates .xml
rm ClinVarVCVRelease.xml.gz  # Delete .gz to save 4GB
```

---

## API Reference

### `load_clinvar_file()`
```python
load_clinvar_file(
    filepath: Path,
    user_chromosomes: Optional[Set[str]] = None,
    checkpoint_dir: Optional[Path] = None,
) -> pd.DataFrame
```

**Auto-detects file type and best loading mode.**

**Parameters:**
- `filepath`: Path to ClinVar file (VCF, XML, variant_summary)
- `user_chromosomes`: Optional chromosome filter (enables lazy/indexed)
- `checkpoint_dir`: Optional cache directory

**Returns:** DataFrame with variant data

---

### `get_user_chromosomes()`
```python
from varidex.io.matching_improved import get_user_chromosomes

chromosomes: Set[str] = get_user_chromosomes(user_df)
```

**Extracts unique chromosomes from user genome.**

**Parameters:**
- `user_df`: User genome DataFrame with 'chromosome' column

**Returns:** Set of chromosome names (e.g., `{'1', '7', '19', 'X'}`)

---

### `build_xml_index()`
```python
from varidex.io.indexers import build_xml_index

index = build_xml_index(
    xml_path: Path,
    force_rebuild: bool = False,
)
```

**Builds byte-offset index for XML file.**

**Parameters:**
- `xml_path`: Path to UNCOMPRESSED XML
- `force_rebuild`: Rebuild even if cached

**Returns:** Index dict

**Performance:** 20-30 min first run, <1s cached

---

## Version History

- **v8.2.0** - Phase 3: Indexed mode (30-60s, <500MB RAM)
- **v8.1.0** - Phase 2: Lazy loading (chromosome filtering)
- **v8.0.0** - Phase 1: Streaming parser (5-8 min, 2-4GB RAM)
- **v7.x.x** - VCF/TSV support only

---

## Support

If you encounter issues:

1. Check memory requirements (streaming needs 4-8GB)
2. Try indexed mode for low memory
3. Fall back to VCF if XML doesn't work
4. Check GitHub issues: [VariDex Issues](https://github.com/Plantucha/VariDex/issues)

---

**Congratulations! You now have the fastest, most memory-efficient ClinVar XML loading available!** ðŸŽ‰
