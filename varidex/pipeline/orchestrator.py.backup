#!/usr/bin/env python3
"""
varidex/pipeline/orchestrator.py - Pipeline Orchestrator v6.0.0

Main 7-stage pipeline coordinator.

Fixes from v5.3.0:
- Centralized imports (varidex._imports)
- Standardized config access
- File detection with strict mode
- User interaction flags (--force, --non-interactive)

This file contains:
- Import fallback system
- Configuration helpers
- Utility functions
- Main coordination loop
- CLI entry point

Stage implementations are in varidex/pipeline/stages.py
"""
import sys
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, Optional

# ============================================================================
# LOGGING - MUST BE FIRST
# ============================================================================
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[logging.FileHandler('pipeline.log'), logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

# ============================================================================
# CENTRALIZED IMPORTS - PRESERVE EXACT LINES 36-78
# ============================================================================

try:
    from varidex import _imports
    config = _imports.get_config()
    models = _imports.get_models()
    loader = _imports.get_loader()
    reports = _imports.get_reports()
    PipelineState = models.PipelineState
    logger.info("‚úì Centralized imports loaded")
    _IMPORT_MODE = 'centralized'
except ImportError as e:
    logger.warning(f"Import manager unavailable: {e}")
    logger.info("‚úì Falling back to direct imports")

    from file_2_models import PipelineState
    from file_5_loader import (
        load_clinvar_file, load_23andme_file, load_vcf_file,
        detect_clinvar_file_type, match_variants_hybrid
    )
    from file_6a_report_generator import create_results_dataframe, generate_all_reports

    config = sys.modules[__name__]

    class _LoaderWrapper:
        load_clinvar_file = staticmethod(load_clinvar_file)
        load_23andme_file = staticmethod(load_23andme_file)
        load_vcf_file = staticmethod(load_vcf_file)
        detect_clinvar_file_type = staticmethod(detect_clinvar_file_type)
        match_variants_hybrid = staticmethod(match_variants_hybrid)

    class _ReportsWrapper:
        create_results_dataframe = staticmethod(create_results_dataframe)
        generate_all_reports = staticmethod(generate_all_reports)

    loader = _LoaderWrapper()
    reports = _ReportsWrapper()
    _IMPORT_MODE = 'fallback'

# Import stage implementations (new)
from varidex.pipeline.stages import (
    execute_stage2_load_clinvar,
    execute_stage3_load_user_data,
    execute_stage4_hybrid_matching,
    execute_stage5_acmg_classification,
    execute_stage6_create_results,
    execute_stage7_generate_reports
)

# ============================================================================
# YAML CONFIG - PRESERVE EXACT LINES 80-120
# ============================================================================

def load_yaml_config(config_path: Path = Path('.varidex.yaml')) -> Dict:
    """Load YAML config file."""
    if not config_path.exists():
        return {}
    try:
        import yaml
        with open(config_path, 'r') as f:
            cfg = yaml.safe_load(f)
        logger.info(f"‚úì Loaded config: {config_path}")
        return cfg or {}
    except ImportError:
        logger.warning("PyYAML not installed")
        return {}
    except Exception as e:
        logger.warning(f"Config load failed: {e}")
        return {}

def get_safeguard_config(yaml_config: Dict) -> Dict:
    """Merge ENV > YAML > defaults."""
    defaults = {
        'max_error_rate': 0.05,
        'max_validation_error_rate': 0.10,
        'abort_on_threshold': True,
        'enable_validation': True,
        'error_log_path': 'results/classification_errors.log',
        'clinvar_max_age_days': 45
    }
    cfg = defaults.copy()
    cfg.update(yaml_config.get('safeguards', {}))
    cfg['max_error_rate'] = float(os.getenv('MAX_ERROR_RATE', cfg['max_error_rate']))
    cfg['max_validation_error_rate'] = float(
        os.getenv('MAX_VALIDATION_ERROR_RATE', cfg['max_validation_error_rate'])
    )
    cfg['abort_on_threshold'] = os.getenv('GRACEFUL_MODE', 'false').lower() != 'true'
    return cfg

# ============================================================================
# UTILITIES - PRESERVE EXACT LINES 122-190
# ============================================================================

class FileTypeDetectionError(Exception):
    """Raised when file type is ambiguous."""

def get_config_value(name: str, default=None):
    """Get config value safely."""
    try:
        return getattr(config, name, default)
    except (AttributeError, TypeError):
        return default

def detect_data_file_type(file_path: Path, strict: bool = True) -> str:
    """Auto-detect format: vcf|23andme|position_tsv."""
    logger.info(f"  Detecting: {file_path.name}")
    try:
        if str(file_path).endswith('.gz'):
            import gzip
            with gzip.open(file_path, 'rt') as f:
                first_line = f.readline().lower()
        else:
            with open(file_path, 'r') as f:
                first_line = f.readline().lower()

        if first_line.startswith('##fileformat=vcf') or first_line.startswith('#chrom'):
            logger.info("    ‚Üí VCF")
            return 'vcf'
        if 'rsid' in first_line and 'chromosome' in first_line and 'genotype' in first_line:
            logger.info("    ‚Üí 23andMe")
            return '23andme'
        if 'chromosome' in first_line and 'position' in first_line:
            logger.info("    ‚Üí Position TSV")
            return 'position_tsv'

        if strict:
            raise FileTypeDetectionError(
                f"Cannot detect file type for {file_path.name}. "
                f"Use --format vcf|23andme|tsv"
            )
        logger.warning(f"    ‚Üí Defaulting to 23andMe (AMBIGUOUS)")
        return '23andme'
    except IOError as e:
        if strict:
            raise FileTypeDetectionError(f"Cannot read file: {e}")
        logger.warning(f"Detection failed: {e}, defaulting to 23andMe")
        return '23andme'

def check_clinvar_freshness(file_path: Path, max_age_days: int = 45, 
                            force: bool = False, interactive: bool = True) -> bool:
    """Check ClinVar age."""
    if force:
        logger.info("  ‚ö° Skipping check (--force)")
        return True

    mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
    days_old = (datetime.now() - mtime).days

    if days_old > max_age_days:
        msg = f"‚ö†Ô∏è  ClinVar is {days_old} days old (max: {max_age_days})"
        logger.warning(msg)
        if not interactive:
            raise ValueError(f"{msg}. Use --force to override")
        response = input("   Continue? (yes): ")
        if response.lower() != 'yes':
            return False
    else:
        logger.info(f"  ‚úì ClinVar OK ({days_old} days)")
    return True

# ============================================================================
# MAIN PIPELINE - SIMPLIFIED (390 lines ‚Üí 120 lines)
# ============================================================================

def main(clinvar_path: str, user_data_path: str, force: bool = False,
         interactive: bool = True, user_format: Optional[str] = None,
         yaml_config_path: Optional[Path] = None) -> bool:
    """Execute 7-stage pipeline.

    Coordination only - implementations in stages.py.
    """
    print("=" * 70)
    print("CLINVAR-WGS PIPELINE v6.0.0")
    print("=" * 70)
    print(f"Start: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    yaml_cfg = load_yaml_config(yaml_config_path or Path('.varidex.yaml'))
    SAFEGUARD_CONFIG = get_safeguard_config(yaml_cfg)

    if not SAFEGUARD_CONFIG['abort_on_threshold']:
        print("‚ö†Ô∏è  GRACEFUL MODE")
    if force:
        print("‚ö° FORCE MODE")
    if not interactive:
        print("ü§ñ NON-INTERACTIVE")
    print()

    clinvar_file = Path(clinvar_path)
    user_file = Path(user_data_path)
    state = PipelineState()

    try:
        # STAGE 1: FILE ANALYSIS (orchestration only)
        print("=" * 70)
        print("[1/7] üìã FILE ANALYSIS")
        print("=" * 70)

        if not clinvar_file.exists():
            raise FileNotFoundError(f"ClinVar not found: {clinvar_file}")
        if not user_file.exists():
            raise FileNotFoundError(f"User data not found: {user_file}")

        if not check_clinvar_freshness(
            clinvar_file, 
            max_age_days=SAFEGUARD_CONFIG['clinvar_max_age_days'],
            force=force,
            interactive=interactive
        ):
            return False

        clinvar_type = loader.detect_clinvar_file_type(clinvar_file)
        user_type = user_format or detect_data_file_type(user_file, strict=not force)
        match_mode = get_config_value('MATCH_MODE', 'hybrid')

        print(f"  ClinVar: {clinvar_type}")
        print(f"  User: {user_type}")
        print(f"  Mode: {match_mode}")
        state.file_types = f"{clinvar_type}/{user_type}"

        # STAGE 2: LOAD CLINVAR (delegated to stages.py)
        print()
        print("=" * 70)
        print("[2/7] üì• LOADING CLINVAR")
        print("=" * 70)

        checkpoint_dir = get_config_value('CHECKPOINT_DIR', Path('.varidex_cache'))
        if not isinstance(checkpoint_dir, Path):
            checkpoint_dir = Path(checkpoint_dir)

        clinvar_df = execute_stage2_load_clinvar(
            clinvar_file,
            checkpoint_dir,
            loader,
            SAFEGUARD_CONFIG,
            _IMPORT_MODE
        )

        state.variants_loaded = len(clinvar_df)
        logger.info(f"‚úì Loaded {state.variants_loaded:,} ClinVar variants")
        print(f"  ‚úì Loaded: {state.variants_loaded:,} variants")

        # STAGE 3: LOAD USER DATA (delegated to stages.py)
        print()
        print("=" * 70)
        print("[3/7] üì• LOADING USER DATA")
        print("=" * 70)

        user_df = execute_stage3_load_user_data(
            user_file,
            user_type,
            loader
        )

        state.user_variants = len(user_df)
        logger.info(f"‚úì Loaded {state.user_variants:,} user variants")
        print(f"  ‚úì Loaded: {state.user_variants:,} variants")

        # STAGE 4: HYBRID MATCHING (delegated to stages.py)
        print()
        print("=" * 70)
        print("[4/7] üîó HYBRID MATCHING")
        print("=" * 70)

        matched_df = execute_stage4_hybrid_matching(
            clinvar_df,
            user_df,
            clinvar_type,
            user_type,
            loader,
            SAFEGUARD_CONFIG,
            _IMPORT_MODE
        )

        state.matches = len(matched_df)
        if state.matches == 0:
            raise ValueError("No matches! Check formats & coordinates")

        match_rate = (state.matches / state.user_variants * 100) if state.user_variants > 0 else 0
        logger.info(f"‚úì Matched {state.matches:,} variants ({match_rate:.1f}%)")
        print(f"  ‚úì Matched: {state.matches:,} ({match_rate:.1f}%)")

        # STAGE 5: ACMG CLASSIFICATION (delegated to stages.py)
        print()
        print("=" * 70)
        print("[5/7] üß¨ ACMG CLASSIFICATION")
        print("=" * 70)

        classified_variants, stats = execute_stage5_acmg_classification(
            matched_df,
            SAFEGUARD_CONFIG,
            clinvar_type,
            user_type,
            _IMPORT_MODE
        )

        if not classified_variants:
            raise ValueError("Classification failed")

        logger.info(f"‚úì Classified {len(classified_variants):,} variants")
        print(f"  ‚úì Classified: {len(classified_variants):,} variants")
        print(f"    ‚Ä¢ Pathogenic: {stats.get('pathogenic', 0):,}")
        print(f"    ‚Ä¢ Likely Pathogenic: {stats.get('likely_pathogenic', 0):,}")
        print(f"    ‚Ä¢ VUS: {stats.get('vus', 0):,}")
        print(f"    ‚Ä¢ Likely Benign: {stats.get('likely_benign', 0):,}")
        print(f"    ‚Ä¢ Benign: {stats.get('benign', 0):,}")

        if stats.get('conflicts', 0) > 0:
            print(f"    ‚ö†Ô∏è  Conflicts: {stats['conflicts']:,}")

        # STAGE 6: CREATE RESULTS (delegated to stages.py)
        print()
        print("=" * 70)
        print("[6/7] üìä CREATE RESULTS")
        print("=" * 70)

        results_df = execute_stage6_create_results(
            classified_variants,
            reports
        )

        logger.info(f"‚úì DataFrame: {len(results_df):,} rows")
        print(f"  ‚úì DataFrame: {len(results_df):,} variants")

        # STAGE 7: GENERATE REPORTS (delegated to stages.py)
        print()
        print("=" * 70)
        print("[7/7] üìÑ GENERATE REPORTS")
        print("=" * 70)

        output_dir = Path('results')
        output_dir.mkdir(exist_ok=True, parents=True)

        report_files = execute_stage7_generate_reports(
            results_df,
            stats,
            output_dir,
            reports
        )

        print(f"\n  ‚úì Reports in: {output_dir.absolute()}/")
        for report_type, path in report_files.items():
            print(f"    ‚Ä¢ {report_type.upper()}: {path.name}")

        # COMPLETE
        print()
        print("=" * 70)
        print("‚úÖ PIPELINE COMPLETE")
        print("=" * 70)
        print(f"Coverage: {state.matches:,}/{state.user_variants:,} ({match_rate:.1f}%)")
        print(f"Pathogenic: {stats.get('pathogenic', 0):,} | "
              f"Likely Pathogenic: {stats.get('likely_pathogenic', 0):,} | "
              f"VUS: {stats.get('vus', 0):,}")

        print(f"\nReports:")
        for rtype, path in report_files.items():
            size_kb = path.stat().st_size / 1024
            print(f"  ‚Ä¢ {rtype.upper()}: {path.name} ({size_kb:.1f} KB)")

        print("\n‚ö†Ô∏è  RESEARCH USE ONLY - Consult genetic counselor")
        print("=" * 70)
        logger.info("Pipeline completed")
        return True

    except FileNotFoundError as e:
        logger.error(f"File not found: {e}")
        print(f"\n‚ùå ERROR: {e}")
        return False
    except FileTypeDetectionError as e:
        logger.error(f"Detection failed: {e}")
        print(f"\n‚ùå ERROR: {e}")
        return False
    except ValueError as e:
        logger.error(f"Validation error: {e}")
        print(f"\n‚ùå ERROR: {e}")
        return False
    except ImportError as e:
        logger.error(f"Import error: {e}")
        print(f"\n‚ùå ERROR: {e}")
        return False
    except Exception as e:
        logger.error(f"Pipeline failed: {e}", exc_info=True)
        print(f"\n‚ùå ERROR: {e}\n   Check pipeline.log")
        return False

# ============================================================================
# CLI - PRESERVE EXACT LINES 583-END
# ============================================================================

def print_usage() -> None:
    """Print usage."""
    print("""
CLINVAR-WGS PIPELINE v6.0.0 (PRODUCTION)

USAGE:
    python -m varidex.pipeline <clinvar_file> <user_data> [OPTIONS]

OPTIONS:
    --force             Skip ClinVar freshness check
    --non-interactive   Disable prompts
    --format FORMAT     vcf|23andme|tsv
    --config FILE       YAML config
    --help              Show help

EXAMPLES:
    python -m varidex.pipeline clinvar.txt genome.txt
    python -m varidex.pipeline clinvar.vcf data.vcf --force --non-interactive
    python -m varidex.pipeline clinvar.txt data.vcf --format vcf

‚ö†Ô∏è  RESEARCH USE ONLY
Reference: Richards et al. 2015, PMID 25741868
""")

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(
        description='ClinVar-WGS ACMG Variant Classification v6.0.0',
        add_help=False
    )
    parser.add_argument('clinvar_file', nargs='?')
    parser.add_argument('user_data', nargs='?')
    parser.add_argument('--force', action='store_true')
    parser.add_argument('--non-interactive', action='store_true')
    parser.add_argument('--format', choices=['vcf', '23andme', 'tsv'])
    parser.add_argument('--config', type=Path)
    parser.add_argument('--help', action='store_true')

    args = parser.parse_args()

    if args.help or not args.clinvar_file or not args.user_data:
        print_usage()
        sys.exit(0 if args.help else 1)

    success = main(
        args.clinvar_file,
        args.user_data,
        force=args.force,
        interactive=not args.non_interactive,
        user_format=args.format,
        yaml_config_path=args.config
    )

    sys.exit(0 if success else 1)
