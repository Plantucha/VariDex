#!/usr/bin/env python3
"""
varidex/io/normalization.py - Coordinate normalization utilities (DEVELOPMENT)

Responsibilities:
- Normalize chromosome and position columns.
- Left-align and normalize indel representations.
- Generate a stable coord_key for joining between datasets.

This module is used by ClinVar loaders and matching code to ensure that
coordinates are comparable across different sources.
"""

from __future__ import annotations

import logging
from multiprocessing import Pool, cpu_count
from typing import List, Optional, Tuple

import pandas as pd
from tqdm import tqdm

logger = logging.getLogger(__name__)

COORD_COLUMNS: List[str] = ["chromosome", "position", "ref_allele", "alt_allele"]


def _ensure_coord_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    Ensure required coordinate columns exist.

    Missing columns are created with NA values so downstream code
    can rely on their presence.
    """
    df = df.copy()
    for col in COORD_COLUMNS:
        if col not in df.columns:
            df[col] = pd.NA
    return df


def _normalize_position_dtype(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cast position to integer-like dtype where possible.
    """
    if "position" not in df.columns:
        return df

    df = df.copy()
    # Safely coerce to numeric; invalid values become NaN
    df["position"] = pd.to_numeric(df["position"], errors="coerce")
    # Drop rows with invalid / missing positions
    before = len(df)
    df = df[df["position"].notna()].copy()
    after = len(df)
    if after < before:
        logger.info("Dropped %d rows with invalid positions", before - after)

    # Use Int64 (nullable) to preserve NA semantics if needed
    df["position"] = df["position"].astype("Int64")
    return df


def _standardize_chromosome(df: pd.DataFrame) -> pd.DataFrame:
    """
    Standardize chromosome names to simple forms like 1..22, X, Y, MT.
    """
    if "chromosome" not in df.columns:
        return df

    df = df.copy()
    chrom = df["chromosome"].astype(str).str.upper()

    # Strip common prefixes like "CHR"
    chrom = chrom.str.replace(r"^CHR", "", regex=True)

    # Normalize mitochondrial notation
    chrom = chrom.replace({"M": "MT", "MTDNA": "MT"})

    df["chromosome"] = chrom
    return df


def _build_coord_key(
    chrom: pd.Series,
    pos: pd.Series,
    ref: pd.Series,
    alt: pd.Series,
) -> pd.Series:
    """
    Build coord_key of the form 'CHR:POS:REF:ALT'.

    All components are converted to uppercase string.
    """
    chrom_str = chrom.astype(str).str.upper()
    ref_str = ref.astype(str).str.upper()
    alt_str = alt.astype(str).str.upper()
    pos_str = pos.astype(str)

    return chrom_str + ":" + pos_str + ":" + ref_str + ":" + alt_str


def _left_align_variants_sequential(df: pd.DataFrame) -> pd.DataFrame:
    """
    Original (sequential) left-alignment implementation.

    NOTE:
    - This function intentionally uses row-wise access (df.at[idx, ...]),
      which is slow for millions of rows but preserves existing semantics.
    - It is wrapped by left_align_variants() which can parallelize it
      over chunks for large datasets.
    """
    if df is None or len(df) == 0:
        return df

    df = df.copy()

    # Ensure required columns exist
    df = _ensure_coord_columns(df)

    for idx in df.index:
        # Skip rows with missing alleles
        if pd.isna(df.at[idx, "ref_allele"]) or pd.isna(df.at[idx, "alt_allele"]):
            continue

        ref = str(df.at[idx, "ref_allele"])
        alt = str(df.at[idx, "alt_allele"])

        # Uppercase for consistency
        ref = ref.upper()
        alt = alt.upper()

        # Trim identical prefix bases
        # Example: ref = ACGT, alt = ACT -> trim common "A" prefix
        while len(ref) > 1 and len(alt) > 1 and ref[0] == alt[0]:
            ref = ref[1:]
            alt = alt[1:]

        # Trim identical suffix bases
        # Example: ref = TCG, alt = TAG -> trim common "G" suffix
        while len(ref) > 1 and len(alt) > 1 and ref[-1] == alt[-1]:
            ref = ref[:-1]
            alt = alt[:-1]

        df.at[idx, "ref_allele"] = ref
        df.at[idx, "alt_allele"] = alt

    return df


def _left_align_chunk(args: Tuple[pd.DataFrame, int]) -> Tuple[pd.DataFrame, int]:
    """
    Worker wrapper: run sequential left-alignment on a single chunk.

    Args:
        args: (DataFrame chunk, chunk_index)

    Returns:
        (processed_chunk, chunk_index)
    """
    chunk, chunk_idx = args
    result = _left_align_variants_sequential(chunk)
    return result, chunk_idx


def left_align_variants(
    df: pd.DataFrame,
    n_workers: Optional[int] = None,
) -> pd.DataFrame:
    """
    Parallel left-alignment wrapper.

    For large datasets, splits the input into chunks and runs the original
    sequential logic in parallel worker processes. For small datasets,
    falls back to the sequential implementation to avoid overhead.

    Args:
        df: Variants DataFrame.
        n_workers: Optional worker count; defaults to (CPU count - 1).

    Returns:
        DataFrame with left-aligned variant alleles.
    """
    n_rows = len(df)
    if n_rows == 0:
        return df

    # For small inputs, avoid multiprocessing overhead
    if n_rows < 100_000:
        return _left_align_variants_sequential(df)

    if n_workers is None:
        n_workers = max(1, cpu_count() - 1)

    orig_len = n_rows

    # Aim for about 4 chunks per worker, but not smaller than 50k
    chunk_size = max(50_000, n_rows // (n_workers * 4))
    chunks: List[Tuple[pd.DataFrame, int]] = []
    chunk_idx = 0

    for start in range(0, n_rows, chunk_size):
        stop = start + chunk_size
        # Copy slice so worker can safely mutate it
        chunk = df.iloc[start:stop].copy()
        chunks.append((chunk, chunk_idx))
        chunk_idx += 1

    print(
        f"  ⚡ Left-aligning {orig_len:,} variants in "
        f"{len(chunks)} chunks, {n_workers} workers"
    )

    try:
        with Pool(processes=n_workers) as pool:
            results = list(
                tqdm(
                    pool.imap(_left_align_chunk, chunks),
                    total=len(chunks),
                    desc="  Left-aligning",
                    unit="chunk",
                    leave=False,
                )
            )
    except Exception as exc:
        logger.warning(
            "Parallel left-alignment failed (%s), falling back to sequential",
            exc,
        )
        return _left_align_variants_sequential(df)

    # Reassemble chunks in the original order by chunk index
    results_sorted = sorted(results, key=lambda x: x[1])
    aligned_chunks = [chunk for chunk, _idx in results_sorted]
    result = pd.concat(aligned_chunks, ignore_index=True)

    if len(result) != orig_len:
        logger.warning(
            "Left-alignment changed row count: %d → %d", orig_len, len(result)
        )

    return result


def create_coord_key(df: pd.DataFrame) -> pd.DataFrame:
    """
    Normalize alleles and create a coord_key column.

    Steps:
    - Ensure coordinate columns exist.
    - Drop rows with missing coordinates.
    - Left-align alleles (parallel for large inputs).
    - Build coord_key: CHR:POS:REF:ALT.
    """
    if df is None or len(df) == 0:
        return df

    df = df.copy()
    df = _ensure_coord_columns(df)

    # Drop rows with missing core coordinates
    mask_valid = (
        df["chromosome"].notna()
        & df["position"].notna()
        & df["ref_allele"].notna()
        & df["alt_allele"].notna()
    )
    before = len(df)
    df = df[mask_valid].copy()
    after = len(df)
    if after < before:
        logger.info("Dropped %d rows without complete coordinates", before - after)

    # Left-align alleles (may run in parallel)
    df = left_align_variants(df)

    # Build coord_key
    df["coord_key"] = _build_coord_key(
        df["chromosome"],
        df["position"],
        df["ref_allele"],
        df["alt_allele"],
    )

    return df


def normalize_dataframe_coordinates(df: pd.DataFrame) -> pd.DataFrame:
    """
    High-level normalization entry point.

    This is what ClinVar loaders call after basic chromosome/position
    validation to get a fully normalized DataFrame with coord_key.

    Steps:
    - Ensure coordinate columns exist.
    - Standardize chromosome values.
    - Normalize position dtype.
    - Create coord_key via left_align_variants().
    """
    if df is None or len(df) == 0:
        return df

    df = df.copy()
    df = _ensure_coord_columns(df)
    df = _standardize_chromosome(df)
    df = _normalize_position_dtype(df)
    df = create_coord_key(df)

    return df


__all__ = [
    "normalize_dataframe_coordinates",
    "create_coord_key",
    "left_align_variants",
]
